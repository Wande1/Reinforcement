# Reinforcement
MDP APPROACH FOR 2*2 GRID EXAMPLE
Example; Learning an agent travelling through a 2*2 grid (4 states)
Red wall prevents direct moves from S1 to S2
States S1, S2, S3 give reward of -1; state S4 gives reward of +10
Action: Left, Right Up, and Down



MDP policy Iteration
These transistion matrices reflect the following randomness of action taken vis a vis an action, there is a 70% probability that that action selected will occur. 
There is a 20% probability the agent will stay in the same (no action taken). 
And there is a 10% probability that the agent will move in lateral direction to the action selected.
